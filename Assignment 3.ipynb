{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-f28b1ae2c62e>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-f28b1ae2c62e>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    completeData = .loadtxt(os.path.join('Data', 'house_data_complete.csv'), delimiter=',')\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "\n",
    "completeData = .loadtxt(os.path.join('Data', 'house_data_complete.csv'), delimiter=',')\n",
    "for i in range(3):\n",
    "    training, validation, testing = np.split(completeData.sample(frac=1), [int(.6*len(completeData)),int(.8*len(completeData))])\n",
    "\n",
    "    pyplot.plot(training.values[:,3], training.values[:,2], 'ro', ms=10, mec='k')\n",
    "    pyplot.ylabel('Prices')\n",
    "    pyplot.xlabel('Bedrooms')\n",
    "    #pyplot.show()\n",
    "    lamArr = [0, 0.001, 0.002, 0.004]\n",
    "    m= training.values[:,2].size\n",
    "    mT = testing.values[:,2].size\n",
    "    mV = validation.values[:,2].size\n",
    "    def featureNormalize(X):\n",
    "        mu = np.mean(X, axis=0)\n",
    "        sigma = np.std(X, axis=0)\n",
    "        X_norm = (X - mu) / sigma\n",
    "        return X_norm, mu, sigma\n",
    "\n",
    "    testing = testing.drop(columns=['price', 'date']).values\n",
    "    testing= testing[:,1:5]\n",
    "    t_norm, mu, sigma = featureNormalize(testing)\n",
    "    testing = np.concatenate([np.ones((mT, 1)), t_norm], axis=1)\n",
    "\n",
    "    validation = validation.drop(columns=['price', 'date']).values\n",
    "    validation= validation[:,1:5]\n",
    "    v_norm, mu, sigma = featureNormalize(validation)\n",
    "    validation = np.concatenate([np.ones((mV, 1)), v_norm], axis=1)\n",
    "\n",
    "    X = training.drop(columns=['price', 'date']).values\n",
    "    X= X[:,1:5]\n",
    "    X_norm, mu, sigma = featureNormalize(X)\n",
    "    print('Computed mean:', mu)\n",
    "    print('Computed standard deviation:', sigma)\n",
    "    X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)\n",
    "\n",
    "    initial_theta = np.zeros(X.shape[1])\n",
    "    h1 = np.dot(X, initial_theta)\n",
    "    h2 = np.dot(np.power(X,2) , initial_theta)\n",
    "    ktr = X.copy()\n",
    "    ktr[:, 2] = np.power(ktr[:, 2], 2)\n",
    "    h3 = np.dot(ktr , initial_theta)\n",
    "\n",
    "    h1t = np.dot(testing, initial_theta)\n",
    "    h2t = np.dot(np.power(testing,2) , initial_theta)\n",
    "    kte = testing.copy()\n",
    "    kte[:, 2] = np.power(kte[:, 2], 2)\n",
    "    h3t = np.dot(kte , initial_theta)\n",
    "\n",
    "    h1v = np.dot(validation, initial_theta)\n",
    "    h2v = np.dot(np.power(validation,2) , initial_theta)\n",
    "    kv = validation.copy()\n",
    "    kv[:, 2] = np.power(kv[:, 2], 2)\n",
    "    h3v = np.dot(kv , initial_theta)\n",
    "\n",
    "    y = training.values[:,2]\n",
    "    yT = testing[:,2]\n",
    "    yV = validation[:,2]\n",
    "\n",
    "    def costFunctionReg(theta, X, y, h, lambda_, m):\n",
    "        J= np.dot((h - y), (h - y)) / (2 * m) + ((lambda_/(2 * m))* np.sum(np.dot(theta, theta)))\n",
    "        return J\n",
    "    def costFunction(y, h, m):\n",
    "        J= np.dot((h - y), (h - y)) / (2 * m)\n",
    "        return J\n",
    "    aH1 =[]\n",
    "    aH2 =[]\n",
    "    aH3 =[]\n",
    "    t1= []\n",
    "    t2= []\n",
    "    t3 = []\n",
    "\n",
    "    #for i in lamArr:\n",
    "       # cost =  costFunctionReg(initial_theta, validation, yV, h1v, i, mV)\n",
    "      #  cost2 = costFunctionReg(initial_theta, validation, yV, h2v, i, mV)\n",
    "     #   cost3 = costFunctionReg(initial_theta, validation, yV, h3v, i, mV)\n",
    "    #    aH1.append(cost)\n",
    "    #    aH2.append(cost2)\n",
    "    #    aH3.append(cost3)\n",
    "    #lambda_1= lamArr[min(range(len(aH1)), key=aH1.__getitem__)]\n",
    "    #lambda_2= lamArr[min(range(len(aH2)), key=aH2.__getitem__)]\n",
    "    #lambda_3= lamArr[min(range(len(aH3)), key=aH3.__getitem__)]\n",
    "\n",
    "    for i in lamArr:\n",
    "        lambda_ = i\n",
    "        cost = costFunctionReg(initial_theta, X, y, h1, lambda_, m)\n",
    "        cost2 = costFunctionReg(initial_theta, X, y, h2, lambda_, m)\n",
    "        cost3 = costFunctionReg(initial_theta, ktr, y, h3, lambda_, m)\n",
    "        print('Cost at initial theta (zeros): {:.3f}'.format(cost3))\n",
    "        def gradientDescent(X, y, theta, alpha, num_iters, lambda_):\n",
    "            m = y.shape[0]  # number of training examples\n",
    "            theta = theta.copy()\n",
    "            J_history = []  # Use a python list to save cost in every iteration\n",
    "\n",
    "            for i in range(num_iters):\n",
    "                alphabym = alpha / m\n",
    "                h = np.dot(X, theta)\n",
    "                theta = theta*(1 - (alpha*lambda_)/m) - ((alpha / m) * (np.dot(X.T, h - y)))\n",
    "                J_history.append(costFunctionReg(theta, X, y, h, lambda_, m))\n",
    "\n",
    "            return theta, J_history\n",
    "\n",
    "        def gradientDescent2(X, y, theta, alpha, num_iters, lambda_):\n",
    "            m = y.shape[0]  # number of training examples\n",
    "            theta = theta.copy()\n",
    "            J_history = []  # Use a python list to save cost in every iteration\n",
    "\n",
    "            for i in range(num_iters):\n",
    "                alphabym = alpha / m\n",
    "                h = np.dot(np.power(X,2), theta)\n",
    "                theta = theta*(1 - (alpha*lambda_)/m) - ((alpha / m) * (np.dot(X.T, h - y)))\n",
    "                J_history.append(costFunctionReg(theta, X, y, h, lambda_, m))\n",
    "\n",
    "            return theta, J_history\n",
    "\n",
    "        def gradientDescent3(X, y, theta, alpha, num_iters, lambda_):\n",
    "            m = y.shape[0]  # number of training examples\n",
    "            theta = theta.copy()\n",
    "            J_history = []  # Use a python list to save cost in every iteration\n",
    "\n",
    "            for i in range(num_iters):\n",
    "                alphabym = alpha / m\n",
    "                h = np.dot(ktr, theta)\n",
    "                theta = theta*(1 - (alpha*lambda_)/m) - ((alpha / m) * (np.dot(X.T, h - y)))\n",
    "                J_history.append(costFunctionReg(theta, X, y, h, lambda_, m))\n",
    "\n",
    "            return theta, J_history\n",
    "\n",
    "        iterations = 150\n",
    "        alpha = 0.01\n",
    "        alpha2 = 0.003\n",
    "        theta, J_history = gradientDescent(X,y, initial_theta, alpha, iterations, i)\n",
    "        theta2, J_history2 = gradientDescent2(X,y, initial_theta, alpha2, iterations, i)\n",
    "        theta3, J_history3 = gradientDescent3(ktr,y, initial_theta, alpha, iterations, i)\n",
    "        h1r = np.dot(validation, theta)\n",
    "        h2r = np.dot(np.power(validation, 2), theta2)\n",
    "        kr = validation.copy()\n",
    "        kr[:, 2] = np.power(kr[:, 2], 2)\n",
    "        h3r = np.dot(kr, theta3)\n",
    "        aH1.append(costFunction(yV, h1r, mV))\n",
    "        aH2.append(costFunction(yV, h2r, mV))\n",
    "        aH3.append(costFunction(yV, h3r, mV))\n",
    "\n",
    "    lambda_1= lamArr[min(range(len(aH1)), key=aH1.__getitem__)]\n",
    "    lambda_2= lamArr[min(range(len(aH2)), key=aH2.__getitem__)]\n",
    "    lambda_3= lamArr[min(range(len(aH3)), key=aH3.__getitem__)]\n",
    "    print(lambda_1, '|',lambda_2, '|',lambda_3)\n",
    "    theta, J_history = gradientDescent(X, y, initial_theta, alpha, iterations, lambda_1)\n",
    "    theta2, J_history2 = gradientDescent2(X, y, initial_theta, alpha2, iterations, lambda_2)\n",
    "    theta3, J_history3 = gradientDescent3(ktr, y, initial_theta, alpha, iterations, lambda_3)\n",
    "\n",
    "    pyplot.figure()\n",
    "    pyplot.plot(np.arange(len(J_history)), J_history, lw=2, label='h1')\n",
    "    pyplot.plot(np.arange(len(J_history2)), J_history2, lw=2, label='h2')\n",
    "    pyplot.plot(np.arange(len(J_history3)), J_history3, lw=2, label='h3')\n",
    "    pyplot.legend()\n",
    "    pyplot.xlabel('Number of iterations')\n",
    "    pyplot.ylabel('Cost Function')\n",
    "    pyplot.show()\n",
    "    jTestH1 = costFunctionReg(theta, testing, yT, h1t, lambda_1, mT)\n",
    "    jTestH2 = costFunctionReg(theta2, testing, yT, h2t, lambda_2, mT)\n",
    "    jTestH3 = costFunctionReg(theta3, testing, yT, h3t, lambda_3, mT)\n",
    "    t1.append(jTestH1)\n",
    "    t2.append(jTestH2)\n",
    "    t3.append(jTestH3)\n",
    "t1Avg = np.mean(t1)\n",
    "t2Avg = np.mean(t2)\n",
    "t3Avg = np.mean(t3)\n",
    "print(t1Avg)\n",
    "print(t2Avg)\n",
    "print(t3Avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
